{"cells":[{"cell_type":"markdown","source":["# HW 4 - Supervised Learning at Scale.\n__`MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Fall 2018`__\n\nIn the first three homeworks you became familiar with the Map-Reduce programming paradigm as manifested in the Hadoop Streaming and Spark frameworks. We explored how different data structures and design patterns can help us manage the computational complexity of an algorithm. As part of this process you implemented both a supervised learning alogorithm (Naive Bayes) and an unsupervised learning algorithm (synonym detection via cosine similarity). In both of these tasks parallelization helped us manage calculations involving a large number of features. However a large feature space isn't the only situation that might prompt us to want to parallelize a machine learning algorithm. In the final two assignments we'll look at cases where the iterative nature of an algorithm is the main driver of its computational complexity (and the reason we might want to parallelize it).\n\nIn this week's assignment we'll perform 3 kinds of linear regression: OLS, Ridge and Lasso. As in previous assignments you will implement the core calculations using Spark RDDs... though we've provided more of a code base than before since the focus of the latter half of the course is more on general machine learning concepts. By the end of this homework you should be able to:  \n* ... __define__ the loss functions for OLS, Ridge and Lasso regression.\n* ... __calculate__ the gradient for each of these loss functions.\n* ... __identify__ which parts of the gradient descent algorithm can be parallelized.\n* ... __implement__ parallelized gradient descent with cross-validation and regularization.\n* ... __compare/contrast__ how L1 and L2 regularization impact model parameters & performance.\n\nAdditional Reference: [Spark 2.2 Documentation - RDD programming guide](https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html)\n\n__Please refer to the `README` for homework submission instructions and additional resources.__"],"metadata":{}},{"cell_type":"markdown","source":["### Notebook Set-Up\nBefore starting your homework run the following cells to confirm your setup."],"metadata":{}},{"cell_type":"code","source":["# imports\nimport re\nimport time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport ast\nimport os"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### Run the next cell to create your directory in dbfs\nYou do not need to understand this scala snippet. It simply dynamically fetches your user directory name so that any files you write can be saved in your own directory."],"metadata":{}},{"cell_type":"code","source":["# RUN THIS CELL AS IS\n# This code snippet reads the user directory name, and stores is in a python variable.\n# Next, it creates a folder inside your home folder, which you will use for files which you save inside this notebook.\nusername = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')\nuserhome = 'dbfs:/user/' + username\nprint(userhome)\nhw4_path = userhome + \"/HW4/\" \nhw4_path_open = '/dbfs' + hw4_path.split(':')[-1] # for use with python open()\ndbutils.fs.mkdirs(hw4_path)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">dbfs:/user/csbikkanur@ischool.berkeley.edu\nOut[197]: True</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# RUN THIS CELL AS IS. You should see 348625. If you do not see this, please let an Instructor or TA know.\nsum = 0\nDATA_PATH = 'dbfs:/mnt/mids-w261/data/HW4/'\nfor item in dbutils.fs.ls(DATA_PATH):\n  sum = sum+item.size\nsum\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[198]: 348625</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# RUN THIS CELL AS IS - A test to make sure your directory is working as expected.\n# You should see a result like:\n# dbfs:/user/youremail@ischool.berkeley.edu/hw4/sample_docs.txt\ndbutils.fs.put(hw4_path+'test.txt',\"hello world\",True)\ndisplay(dbutils.fs.ls(hw4_path))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/OLSloss.csv</td><td>OLSloss.csv</td><td>2500</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/OLSmodels.csv</td><td>OLSmodels.csv</td><td>16492</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/lasso_loss.txt</td><td>lasso_loss.txt</td><td>1996</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/lasso_models.txt</td><td>lasso_models.txt</td><td>10662</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/ols_loss.txt</td><td>ols_loss.txt</td><td>1988</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/ols_models.txt</td><td>ols_models.txt</td><td>10426</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/ridge_loss.txt</td><td>ridge_loss.txt</td><td>1993</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/ridge_models.txt</td><td>ridge_models.txt</td><td>10603</td></tr><tr><td>dbfs:/user/csbikkanur@ischool.berkeley.edu/HW4/test.txt</td><td>test.txt</td><td>11</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"code","source":["sc = spark.sparkContext\nspark"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.74.242.103:41469\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.74.242.103:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":8},{"cell_type":"markdown","source":["# Question 1: Opimization Theory \n\nAs you know from w207, Gradient Descent is an iterative process that seeks to find the optimal parameters for a model given a particular training data set. It does this by using the vector of partial derivatives of a loss function to strategically update parameters in a way that will reduce the loss. In live session 6 you discussed some of the theory behnid why gradient descent works and looked at a small example of gradient descent in the context of linear regression.\n\n### Q1 Tasks:\n\n* __a) short response:__ What are the first and second order conditions for convexity and why do we care about them when performing Gradient Descent?\n\n* __b) short response:__ Explain the relationship between problem domain space and model parameter space in the context of Gradient Descent. In practice, why can't we find the optimal model by simply looking at the error surface in model parameter space?\n\n* __c) short response:__ In the context of Gradient Descent, what is the 'learning rate' and what are the tradeoffs associated with setting this hyperparameter?\n\n* __d) BONUS:__ In the context of OLS, what do we mean by a 'closed form solution' and why is it not scalable?"],"metadata":{}},{"cell_type":"markdown","source":["### Q1 Student Answers:\n> __a)__ \n\n+ **First Order Condition:** For any unconstrained function, the minimum and maximum occurs at the point where the first order derivative \\\\( f'(x) \\\\) equals to zero. In performing Gradient Descent, we set the first derivative of the cost function to zero and measure the derivative of the cost function with respect to the weights so that the optimzation process takes one closer step towards the minimum. This condition is known as first order condition.\n\n+ **Second Order Condition:** For any unconstrained function, if there is exists a first derivative, then the maximum will occur at the point where the second derivative \\\\( f''(x) \\\\) is negative and the minimum will occur at the point where the second derivative \\\\( f''(x) \\\\) is positive. In performing Gradient Descent, for a convex cost function, there exists only one minimum (Global Minimum) for that cost function and no maximum. This condition is known as second order condition. \n\n> __b)__ \n\n+ **Problem Domain Space:** In fitting a model for given data, problem domain space refers to the space where we can visually see how devaint the fitted model to the given data. Usually this space consits of the data_points and the visual representaion of the fitted model.\n\n+ **Model Parameter Space:** In fitting a model for given data, model parameter space refers to the space where we can visualy see how deviant the fitted model to the optimal model. Usually this space consists of the model weights and the cost funciton values to see how far off the model compared to the global minimum. \n\n> __c)__ \n\nGradient Descent update for weights of a model is \\\\( w_j^{t+1} = w_j^t - \\eta * \\frac{\\partial J(w)}{\\partial w} \\\\)\n\nIn performing Gradient Descent, `learning rate` \\\\( \\eta \\\\) determines the step size towards the global minimum. If we have a samll value for learning rate, then the step taken towards the global minimum will be small and takes many iterations to reach the minimum. If we have a large value for learning rate, we may overshoot the global minimum and end up diverging in the cost function. So, we need to consider an optimal learning rate to converge/reach the global minimum on the cost function.\n\n> __d)__ \n\nWe can solve for the optimal weights that are at global minimum using below matrix computation: \n\n\\\\( W = (X^T X)^{-1}X^T Y \\\\)\n\nBy finding the weights using this matrix computation, we do not have to perform the Gradient Descent and all the weights can be solved at once. This is called as the `Closed Form Solution`. But, in most of the case it is not possible to find the inverted matrix for \\\\( (X^T X) \\\\) when the matrix has high dimensions. Thus this solution is not scalable as this solution can not be performed using the MapReduce tasks."],"metadata":{}},{"cell_type":"markdown","source":["# About the Data\n\nFor the main task in this portion of the homework you will use data about red and white Portuguese wines. [This data](http://archive.ics.uci.edu/ml/datasets/Wine+Quality) was made available to the UC Irvine public repository of Machine Learning datasets by researchers at the University of Minho in association with [this paper](https://www.sciencedirect.com/science/article/pii/S0167923609001377?via%3Dihub):\n> P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \nModeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n\nThe dataset includes 12 fields:\n>`fixed acidity`  \n`volatile acidity`  \n`citric acid`  \n`residual sugar`  \n`chlorides`  \n`free sulfur dioxide`  \n`total sulfur dioxide`  \n`density`  \n`pH`  \n`sulphates`  \n`alcohol`  \n`quality`   -- (_a score between 0 and 10_)\n\n__`IMPORTANT NOTE:`__ The outcome variable in our data is a human assigned score ranging from 0 to 10. Since the scores are integers this is actually an ordinal and not numerical outcome varaible. However for the purposes of this assignment we'll treat it as a numerical quantity.\n\nThe data are in two files: one containing red wines and another containing white wines.  Use the following cells to download the data, add a field for red/white, and split it into a test and train set."],"metadata":{}},{"cell_type":"code","source":["headers = dbutils.fs.head(DATA_PATH + '/winequality-red.csv',200)\nheaders = headers.split('\\n')[0]\n#print(headers)\nFIELDS = ['color'] + re.sub('\"', '',headers).split(';')\nprint(FIELDS)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[Truncated to first 200 bytes]\n[&#39;color&#39;, &#39;fixed acidity&#39;, &#39;volatile acidity&#39;, &#39;citric acid&#39;, &#39;residual sugar&#39;, &#39;chlorides&#39;, &#39;free sulfur dioxide&#39;, &#39;total sulfur dioxide&#39;, &#39;density&#39;, &#39;pH&#39;, &#39;sulphates&#39;, &#39;alcohol&#39;, &#39;quality&#39;]\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# RUN THIS CELL AS IS. You should see winequality-red.csv and winequality-white.csv. Please contact an Instructor or TA if you do not see these two files.\ndbutils.fs.ls(DATA_PATH)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[202]: [FileInfo(path=&#39;dbfs:/mnt/mids-w261/data/HW4/titanic/&#39;, name=&#39;titanic/&#39;, size=0),\n FileInfo(path=&#39;dbfs:/mnt/mids-w261/data/HW4/winequality-red.csv&#39;, name=&#39;winequality-red.csv&#39;, size=84199),\n FileInfo(path=&#39;dbfs:/mnt/mids-w261/data/HW4/winequality-white.csv&#39;, name=&#39;winequality-white.csv&#39;, size=264426)]</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# load the raw data into an RDD - RUN THIS CELL AS IS\nredsRDD = sc.textFile(DATA_PATH + '/winequality-red.csv')\\\n            .filter(lambda x: x != headers)\\\n            .map(lambda x: '1;' + x) # set first field 1 to indicate red wine\nwhitesRDD = sc.textFile(DATA_PATH + '/winequality-white.csv')\\\n              .filter(lambda x: x != headers)\\\n              .map(lambda x: '0;' + x) # set first field 0 to indicate white wine"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["redsRDD.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[204]: [&#39;1;7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5&#39;,\n &#39;1;7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5&#39;,\n &#39;1;7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;9.8;5&#39;,\n &#39;1;11.2;0.28;0.56;1.9;0.075;17;60;0.998;3.16;0.58;9.8;6&#39;,\n &#39;1;7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5&#39;]</div>"]}}],"execution_count":15},{"cell_type":"code","source":["whitesRDD.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[205]: [&#39;0;7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6&#39;,\n &#39;0;6.3;0.3;0.34;1.6;0.049;14;132;0.994;3.3;0.49;9.5;6&#39;,\n &#39;0;8.1;0.28;0.4;6.9;0.05;30;97;0.9951;3.26;0.44;10.1;6&#39;,\n &#39;0;7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4;9.9;6&#39;,\n &#39;0;7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4;9.9;6&#39;]</div>"]}}],"execution_count":16},{"cell_type":"code","source":["# Generate 80/20 (pseudo)random train/test split - RUN THIS CELL AS IS\ntrainRDD, heldOutRDD = redsRDD.union(whitesRDD).randomSplit([0.8,0.2], seed = 1)\nprint(f\"... held out {heldOutRDD.count()} records for evaluation and assigned {trainRDD.count()} for training.\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">... held out 1316 records for evaluation and assigned 5181 for training.\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# helper function - RUN THIS CELL AS IS\ndef parse(line):\n    \"\"\"\n    Map record_csv_string --> (tuple,of,fields)\n    \"\"\"\n    fields = np.array(line.split(';'), dtype = 'float')\n    features,quality = fields[:-1], fields[-1]\n    return(features, quality)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["# cache the training set - RUN THIS CELL AS IS \ntrainRDDCached = trainRDD.map(parse).cache()\ntrainRDDCached.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[208]: [(array([ 1.    ,  7.4   ,  0.7   ,  0.    ,  1.9   ,  0.076 , 11.    ,\n         34.    ,  0.9978,  3.51  ,  0.56  ,  9.4   ]), 5.0),\n (array([1.00e+00, 7.80e+00, 7.60e-01, 4.00e-02, 2.30e+00, 9.20e-02,\n         1.50e+01, 5.40e+01, 9.97e-01, 3.26e+00, 6.50e-01, 9.80e+00]), 5.0),\n (array([ 1.   , 11.2  ,  0.28 ,  0.56 ,  1.9  ,  0.075, 17.   , 60.   ,\n          0.998,  3.16 ,  0.58 ,  9.8  ]), 6.0),\n (array([ 1.    ,  7.4   ,  0.7   ,  0.    ,  1.9   ,  0.076 , 11.    ,\n         34.    ,  0.9978,  3.51  ,  0.56  ,  9.4   ]), 5.0),\n (array([ 1.    ,  7.4   ,  0.66  ,  0.    ,  1.8   ,  0.075 , 13.    ,\n         40.    ,  0.9978,  3.51  ,  0.56  ,  9.4   ]), 5.0)]</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["# Question 2: EDA\n\nA statistician's approach to Linear Regression typically involves a series of EDA steps to examine each feature in the data and then a series of steps to test assumptions about their potential contribution to a multi-feature linear model. In particular, we'd want to look for a set of features that exhibit a likely linear relationship with the outcome variable and that are _not_ highy correlated with each other. In the context of machine learning, these considerations remain important techniques for improving model generalizability despite the common practice to use model evaluation techniques (and large data sets) to get the final word on feature selection. \n\nIn this question we'll briefly look at the features in our data set. To mimic an 'at scale' analysis we'll start by sampling from our Spark RDD training set so that we have a manageable amount of data to work with in our visuals.\n\n### Q2 Tasks:\n* __a) short response:__ Run the provided code to sample 1000 points and visualize histograms of each feature. Comment on the distributions you observe (eg. _Which features appear normaly distributed, which don't? Which features vary most/least?_) How is the varaible `color` different than the other features & what does that mean about how we interpret its regression coefficient?\n\n* __b) short response:__ Run the provided code to create boxplots of each feature. Which, if any, appear to have a positive linear relationship with `quality`? Which if any appear to have a negative linear relationship with `quality`?\n\n\n* __c) short response:__ Run the provided code to plot the correlations matrix. Which pairs of features are most _strongly_ (postively or negatively) associated with each other? What implications would that have for our feature selection?"],"metadata":{}},{"cell_type":"markdown","source":["### Q2 Student Answers:\n> __a)__ \n\n+ **`color`** feature is not normally distributed; it is ditributed on **0** and **1** values. So, when the `color` is **1** (`red_wine`), the regression coefficient value of color will be added along with other weights and values. And, when the `color` is **0** (`white_wine`), the regression value will be zero and has no affect on the `quality`\n\n**Normally Distributed Features:**\n+ `citric acid` is normally distributed and has relatively high variance in the data\n+ `density` is normally distributed and has normal variance in the data\n+ `fixed acidity` is normally distributed and has positive skew in the data\n+ `pH` is normally distributed but has normal variance in the data\n+ `sulphates` is normally distributed and has positive skew in the data\n+ `volatile acdity` is normally distributed but has positive skew in the data\n\n**Not Normally Distributed Features:**\n+ `alcohol` is not normally distributed but has high variance in the data\n+ `chlorides` is not normally distributed but has high variance in the data\n+ `free sulfer dioxide` is not normally distributed but has high variance in the data\n+ `residual sugar` is not normally distributed but has high variance in the data\n+ `total sulfer dioxide` is not normally distributed but has high variance in the data\n+ `residual sugar` is not normally distributed but has high variance in the data\n\n\n> __b)__ \n\n+ **Features with a positive linear relationship with `quality`:**\n  * residual sugar\n  * free sulfer dioxide\n  * total sulfer dioxide\n  * alcohol  \n+ **Features with a negative linear relationship with `quality`:**\n  * volatile acidity\n  * chlorides\n  * density\n  \n> __c)__ \nIf we have a strong correlation between the features of a linear regression model, then the statistical significance of the features' contribution to the dependent variable will reduce. Sometimes, this correlation between the features may lead to `multicollinearity` condition. \n\n+ **Pairs of features with strong postive correlation:** \n  * free sulfer dioxide - total sulfer dioxide\n  * volatile acidity - color\n  * density - residual sugar\n  * free sulfer dioxide - residual sugar\n  * total sulfer dioxide - residual sugar\n+ **Pairs of features with strong negative correlation:** \n  * alcohol - density \n  * total sulfer dioxide - color\n  * citric acid - volatile acidity"],"metadata":{}},{"cell_type":"code","source":["# part a - take a 1000 point sample for EDA (RUN THIS CELL AS IS)\nsample = np.array(trainRDDCached.map(lambda x: np.append(x[0], [x[1]]))\n                                .takeSample(False, 1000))\nsample_df = pd.DataFrame(np.array(sample), columns = FIELDS)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["# part a - take a look at histograms for each feature (RUN THIS CELL AS IS)\nsample_df[FIELDS[:-1]].hist(figsize=(15,15), bins=15)\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# part b -  plot boxplots of each feature vs. the outcome (RUN THIS CELL AS IS)\nfig, ax_grid = plt.subplots(4, 3, figsize=(15,15))\ny = sample_df['quality']\nfor idx, feature in enumerate(FIELDS[:-1]):\n    x = sample_df[feature]\n    sns.boxplot(x, y, ax=ax_grid[idx//3][idx%3], orient='h', linewidth=.5)\n    ax_grid[idx//3][idx%3].invert_yaxis()\nfig.suptitle(\"Individual Features vs. Outcome (qualilty)\", fontsize=15, y=0.9)\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# plot heatmap for correlations matrix - RUN THIS CELL AS IS\ncorr = sample_df[FIELDS[:-1]].corr()\nfig, ax = plt.subplots(figsize=(11, 9))\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\ncmap = sns.diverging_palette(240, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=.5)\nplt.title(\"Correlations between features.\")\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["# Question 3: OLS Loss\n\nFor a parametric model, the key factor that will impact how easy it is to optimize is your choice of how to define the loss function. In Ordinary Least Squares (OLS) Regression our loss function is just about as convenient as you will get: not only is it convex, its also very easy to interpret. \n\nWhen doing supervised learning, a simple sanity check consists of comparing one’s estimator against simple rules of thumb. It is useful as a simple baseline to compare with other (real) regressors. Examples of regression baselines include:\n* \"mean\": always predicts the mean of the training set\n* \"median\": always predicts the median of the training set\n* \"quantile\": always predicts a specified quantile of the training set,provided with the quantile parameter.\n* \"constant\": always predicts a constant value that is provided by the user.\n\nIn this question you'll \"choose\" a baseline model and then write a function to compute the loss of a linear model in Spark. You'll reuse this function in Q4 when you implement gradient descent.\n\n#### Baseline example illustrated:"],"metadata":{}},{"cell_type":"code","source":["# points from our mini example from the demo 6 notebook\npoints = np.array([[1,2],[3,4],[5,5],[4,3],[2,3]])\nx = points[:,0]\ny = points[:,1]\n\nplt.figure()\nplt.plot(x, y,'o', label='data points')\nplt.axhline(np.mean(y),c='r', label='\"mean\" model')\nplt.title('Example of \"mean\" baseline model')\nplt.ylabel(\"y\")\nplt.xlabel(\"x\")\nplt.legend()\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["### Q3 Tasks:\n* __a) code:__ Fill in the code below to compute the mean and variance of your outcome variable. [__`HINT:`__ _use `trainRDDCached` as the input & feel free to use Spark built-in functions._]\n\n\n* __b) short response:__ Write the formula for the OLS loss function and explain how to interpret it graphically.\n\n\n* __c) short response:__ In the context of linear models & vector computations what does it mean to 'augment' a data point and why do we do this?\n\n\n* __d) code + short response:__ Fill in the missing code to complete the`OLSLoss` function. Is computing the loss \"embarassingly parallel'? Explain. [__`TIP:`__ Use `augmentedData` as your input when computing the loss.]\n\n* __e) code + short response:__ Fill in the missing code to define a baseline model for this data set that has a bias term equal to the mean of your outcome variable and `0.0` for all coefficients. Note that in the docstring for `OLSLoss` we specified that the model should be a numpy array with the bias in the first position. Once you've defined your model, run the provided cells to check that your model has the correct dimensions and then compute the loss for your baseline model. Compare your results to the result you got in `part a` and explain what you see."],"metadata":{}},{"cell_type":"markdown","source":["### Q3 Student Answers:\n> __b)__ \n\n**OLS Loss Function:**\n\n\\\\( L(w) = \\frac{1}{n}\\sum_{i=1}^{n} [w^T \\cdot x_i - y_i]^2  \\\\)\n\nThis function computes the devaition of the estimated model's predicted values to that of the actual /  ground truth values. This is done by averaging the square of each residual value of the data points. This function is a `Convex Function` and thus it will have a `Global Minimum` at the point where the first derivative of the loss function is zero. I.e. `global minimum` value will occur at `w` where \\\\( L'(w) = 0  \\\\)\n\n> __c)__ \n\nFor a data containing `p` expanatory variables \\\\( x_1, x_2, x_3, ..., x_p \\\\), the OLS regression estimate of the dependent variable \\\\( \\hat{y} \\\\) is given as:\n\n\n\\\\( \\hat{y} = \\beta_0 + \\beta_1  \\cdot x_1 + \\beta_2 \\cdot x_2 + \\beta_3 \\cdot x_3 + ... + \\beta_p \\cdot x_p \\\\)\n\nIn above equation, \\\\( \\beta_0 \\\\) is called as the `bias` and \\\\( \\beta_1, \\beta_2, \\beta_3,..., \\beta_p \\\\) are known as the `weights` of the OLS estimated model. This equation can also be expressed in a matrix notation as below:\n\n\\\\( \\underset{n\\times 1}{\\hat{Y}} =  \\underset{n\\times p+1}{X} \\times \n\\underset{p+1\\times 1}{\\hat{W}}  \\\\)\n\nIn matrix computation, the data `X` can be represented in a matrix notation as \\\\( \\underset{n\\times p}{X} \\\\) and the weights of the model can be represented as \\\\( \\underset{{p+1}\\times 1}{W} \\\\). The data `X` has `n` rows and `p` columns. And, the weights vector has `p+1` entries including the bias term \\\\( \\beta_0 \\\\). For matrix multiplication, we need to have the number of columns of the first matrix to be same as the number of rows of the second matrix. To achieve this, we will add a dummy column (1s)to the data `X` at the first columns to get multiplied by the bias term. This addition of first column to the data is known as **`augmenting the data`** \n\n\n> __d)__ \n\nYes. Computing the OLS loss is `almost-embarassingly parallel`. This is due to the computation of `squaring the residuals of the estimated model` can be performed on different mappers without any dependence. Then we can `sum` these squared residuals to get the numerator part of the OLS function. Then we can divide this value with the total number of records in the data to get the complete solution of the OLS loss. \n\n> __e)__ \n\nOLS loss of `baseline` model is same as the `variance` of the dependent variable `Quality`. This is understandable as the OLS loss function is defined as the average of the squares of the difference between the ground truth values from the predicted values (here it is the `mean` of the ground truth value); thus this equation resolves to the variance of the dependednt value.\n\n\\\\( L(w) = \\frac{1}{n}\\sum_{i=1}^{n} [w^T \\cdot x_i - y_i]^2 \\\\)\n\n\\\\( \\Rightarrow \\frac{1}{n}\\sum_{i=1}^{n} [\\bar{y} - y_i]^2 \\\\)\n\n\\\\( \\Rightarrow variance(y)  \\\\)\n\n\\\\( (\\because w^T \\cdot x_i = \\bar{y})  \\\\)"],"metadata":{}},{"cell_type":"code","source":["# part a - mean and variance of the outcome variable \nmeanQuality = trainRDDCached.map(lambda x: x[1]).mean() # FILL IN YOUR CODE HERE\nvarQuality = trainRDDCached.map(lambda x: x[1]).variance() # FILL IN YOUR CODE HERE\nprint(f\"Mean: {meanQuality}\")\nprint(f\"Variance: {varQuality}\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Mean: 5.811040339702759\nVariance: 0.760086564865664\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["# part d - write function to compute loss (FILL IN MISSING CODE BELOW)\ndef OLSLoss(dataRDD, W):\n    \"\"\"\n    Compute mean squared error.\n    Args:\n        dataRDD - each record is a tuple of (features_array, y)\n        W       - (array) model coefficients with bias at index 0\n    \"\"\"\n    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n    ################## YOUR CODE HERE ##################   \n    loss = augmentedData.map(lambda x: (x[1] - W.dot(x[0]))**2).mean()\n    ################## (END) YOUR CODE ##################\n    return loss"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["# part e - define your baseline model here\nBASELINE = np.array(np.append(meanQuality, [0.0] * len(trainRDDCached.take(1)[0][0])))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["# part e - compute the loss for your baseline model (RUN THIS CELL AS IS)\nassert len(BASELINE) == len(trainRDDCached.take(1)[0][0]) + 1, \"Double check model dimensions\"\nprint(f\"Baseline model loss: {OLSLoss(trainRDDCached, BASELINE)}\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Baseline model loss: 0.7600865648656636\n</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["# Question 4: Vanilla Gradient Descent\n\nPerforming Gradient Descent technically only requires two steps: 1) _use the current model to calculate the gradient_; 2) _use the gradient to update the current model parameters_. In practice though, we'll want to add a third step which is to compute the loss for our new model so that we can see if its working. In this question you'll implement gradient descent for OLS regression and take a look at a few update steps.\n\n### Q4 Tasks:\n* __a) short response:__ Jimi describes the main part of the gradient calculation for OLS Regression using a short mantra: _'the mean of the data weighted by the errors'_. . Write the formula for the gradient and explain how it reflects this phrase. \n\n* __b) short response:__ Looking at the formula you wrote in `part a`, what parts of this calculation can be parallelized and what has to happen after reducing?\n\n\n* __c) code:__ Fill in the missing lines in `GDUpdate` to compute the gradient and perform a single update of the model parameters.   \n    * __`TIP 1:`__ _remember that the gradient is a vector of partial derivatives, `grad` should be a numpy array_    \n    * __`TIP 2:`__ _Spark's built in `mean()` function may help you here_  \n\n\n* __d) short response:__ Run the provided code to perform 5 steps of Gradient Descent on our data. What is wrong with these results?\n\n\n* __e) code + short response:__ Fill in the missing code in `normalize` so that this function scales each feature and centers it at 0. Then use the provide code block to rerun your same gradient descent code on the scaled data. Use these results to explain what the problem was in 'd'.\n    * __`TIP:`__ _You may find [this brief illustration](https://www.coursera.org/lecture/machine-learning/gradient-descent-in-practice-i-feature-scaling-xx3Da) from Andrew Ng's Coursera helpful._"],"metadata":{}},{"cell_type":"markdown","source":["### Q4 Student Answers:\n> __a)__ \n\n**OLS Loss Function:**\n\\\\( L(w) = \\frac{1}{n}\\sum_{i=1}^{n} [w^T \\cdot x_i - y_i]^2  \\\\)\n\nGradient of the OLS regression is the partial derivative of the loss function with respect to `weights` of the model: \n\n\\\\( \\frac{\\partial L(w)}{\\partial w} = \\frac{\\partial \\frac{1}{n}\\sum_{i=1}^{n} [w^T \\cdot x_i - y_i]^2}{\\partial w}  \\\\)\n\n\\\\( \\Rightarrow \\frac{2}{n}\\sum_{i=1}^{n} x_i \\cdot [w^T \\cdot x_i - y_i] \\\\)\n\n\\\\( \\Rightarrow 2 \\cdot \\frac{1}{n}\\sum_{i=1}^{n} x_i \\cdot [w^T \\cdot x_i - y_i] \\\\)\n\nThe first part of the above quation looks like `the mean of the data` and `weighted by the errors of the estimated model`.\n\n> __b)__ \n\n1. From above equation for `gradient` of the OLS loss function, we can parallelize **`the product of the data with residuals:`** \\\\(  x_i \\cdot [w^T \\cdot x_i - y_i] \\\\) \n2. Once this computation is done on the mappers, we can reduce with a `mean()` function and multiply with **2** to get the actual gradient of the OLS loss function. \n\n> __c)__ _complete the coding portions of this question before answering d & e_ \n\n\n\n> __d)__ \n\nFrom the OLS loss values for the first 5 steps, we can see that the loss is not continuously getting reduced. From `step1` to `step2`, there is a huge increase in the loss and from `step2` to `step3`, there is a huge reduce in the loss value. Also, from `step3` to `step4` to `step5`, the loss value is increasing instead of reducing to optimize on the loss function. Apart from this, the `weights` of the updated model are very high in maginitude and requires heavy computation to achive those values.\n\n> __e)__ \n\nFitting OLS model without feature scaling (mean normalization), leads to more steps to reach the global minimum. This is because the features are on a different scale, with each gradient descent update, different features take different magnitude of step size in descending. Also, this could lead to the skewness in reaching the global minimum. If we scale the features, then the convex function will be more similar to a bowl shape and can be reached the global minimum sooner and computationally effective."],"metadata":{}},{"cell_type":"code","source":["# part b - function to perform a single GD step\ndef GDUpdate(dataRDD, W, learningRate = 0.1):\n    \"\"\"\n    Perform one OLS gradient descent step/update.\n    Args:\n        dataRDD - records are tuples of (features_array, y)\n        W       - (array) model coefficients with bias at index 0\n    Returns:\n        new_model - (array) updated coefficients, bias at index 0\n    \"\"\"\n    # add a bias 'feature' of 1 at index 0\n    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n    \n    ################## YOUR CODE HERE ################# \n    grad = 2 * augmentedData.map(lambda x: (W.dot(x[0]) - x[1]) * x[0]).mean()\n    new_model = W - (learningRate * grad)\n    ################## (END) YOUR CODE ################# \n   \n    return new_model"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"code","source":["%%time\n# part c - take a look at a few Gradient Descent steps (RUN THIS CELL AS IS)\n\nnSteps = 5\nmodel = BASELINE\nprint(f\"BASELINE:  Loss = {OLSLoss(trainRDDCached,model)}\")\nfor idx in range(nSteps):\n    print(\"----------\")\n    print(f\"STEP: {idx+1}\")\n    model = GDUpdate(trainRDDCached, model)\n    loss = OLSLoss(trainRDDCached, model)\n    print(f\"Loss: {loss}\")\n    print(f\"Model: {[round(w,3) for w in model]}\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">BASELINE:  Loss = 0.7600865648656636\n----------\nSTEP: 1\nLoss: 3255.0397706648123\nModel: [5.811, -0.009, -0.017, -0.007, 0.002, -0.035, -0.001, 0.167, -0.489, -0.0, 0.0, 0.001, 0.094]\n----------\nSTEP: 2\nLoss: 41538896320.900734\nModel: [15.998, 0.946, 71.311, 3.109, 3.394, 67.104, 0.517, 372.213, 1469.681, 10.133, 32.587, 5.197, 105.407]\n----------\nSTEP: 3\nLoss: 5.321516254246974e+17\nModel: [-36732.224, -3790.819, -257459.013, -11294.195, -12193.785, -240557.886, -1880.28, -1359608.579, -5252902.327, -36544.479, -117571.505, -18781.008, -379946.295]\n----------\nSTEP: 4\nLoss: 6.817355374095457e+24\nModel: [131498780.95, 13574790.866, 921540888.277, 40426173.604, 43645471.549, 861027822.897, 6730358.366, 4867148463.848, 18801163135.814, 130805962.538, 420832007.136, 67225003.981, 1359973545.811]\n----------\nSTEP: 5\nLoss: 8.733663880159665e+31\nModel: [-470665198626.593, -48587550191.15, -3298412689019.937, -144694834630.261, -156217444459.899, -3081821742976.596, -24089547803.278, -17420693064591.215, -67293783870862.79, -468185458548.503, -1506257249668.989, -240614204453.626, -4867666956412.474]\nCPU times: user 100 ms, sys: 0 ns, total: 100 ms\nWall time: 1.13 s\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["# part d - helper function to normalize the data (FILL IN THE MISSING CODE BELOW)\ndef normalize(dataRDD):\n    \"\"\"\n    Scale and center data round mean of each feature.\n    Args:\n        dataRDD - records are tuples of (features_array, y)\n    Returns:\n        normedRDD - records are tuples of (features_array, y)\n    \"\"\"\n    featureMeans = dataRDD.map(lambda x: x[0]).mean()\n    featureStdev = np.sqrt(dataRDD.map(lambda x: x[0]).variance())\n    \n    ################ YOUR CODE HERE #############\n    normedRDD = dataRDD.map(lambda x: ((x[0]-featureMeans)/featureStdev, x[1]))\n    ################ FILL IN YOUR CODE HERE #############\n    \n    return normedRDD"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"code","source":["# part d - cache normalized data (RUN THIS CELL AS IS)\nnormedRDD = normalize(trainRDDCached).cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"code","source":["%%time\n# part e - take a look at a few GD steps w/ normalized data  (RUN THIS CELL AS IS)\nnSteps = 5\nmodel = BASELINE\nprint(f\"BASELINE:  Loss = {OLSLoss(trainRDDCached,model)}\")\nfor idx in range(nSteps):\n    print(\"----------\")\n    print(f\"STEP: {idx+1}\")\n    model = GDUpdate(normedRDD, model)\n    loss = OLSLoss(normedRDD, model) \n    print(f\"Loss: {loss}\")\n    print(f\"Model: {[round(w,3) for w in model]}\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">BASELINE:  Loss = 0.7600865648656636\n----------\nSTEP: 1\nLoss: 0.6555276691703891\nModel: [5.811, -0.02, -0.014, -0.045, 0.014, -0.007, -0.035, 0.009, -0.009, -0.054, 0.003, 0.008, 0.078]\n----------\nSTEP: 2\nLoss: 0.615059239044261\nModel: [5.811, -0.022, -0.014, -0.071, 0.023, -0.006, -0.05, 0.014, -0.021, -0.079, 0.007, 0.024, 0.131]\n----------\nSTEP: 3\nLoss: 0.5935522582531458\nModel: [5.811, -0.018, -0.01, -0.09, 0.03, 0.002, -0.057, 0.02, -0.032, -0.09, 0.011, 0.04, 0.167]\n----------\nSTEP: 4\nLoss: 0.5798853360580277\nModel: [5.811, -0.014, -0.006, -0.105, 0.034, 0.012, -0.061, 0.026, -0.04, -0.094, 0.013, 0.054, 0.195]\n----------\nSTEP: 5\nLoss: 0.5703196233260643\nModel: [5.811, -0.009, -0.003, -0.117, 0.036, 0.024, -0.063, 0.032, -0.047, -0.096, 0.016, 0.066, 0.217]\nCPU times: user 88 ms, sys: 8 ms, total: 96 ms\nWall time: 1.18 s\n</div>"]}}],"execution_count":40},{"cell_type":"markdown","source":["# Question 5: Assessing the performance of your model.\n\nPrinting out the loss as we perform each gradient descent step allows us to confirm that our Gradient Descent code appears to be working, but this number doesn't accurately reflect \"how good\" our model is. In this question you'll plot error curves for a test and training set in order to discuss model performance. Note that although we split out a test & train set when we first loaded the data... in the spirit of keeping that 20% truly 'held out' until then end of the assignment, we'll make an additional split for the purposes of this question dividing the existing training set into two smaller RDDs.\n\n### Q5 Tasks:\n* __a) short response:__ Why doesn't the loss that we printed in Question 4 accurately reflect \"how good\" our model is? \n\n\n* __b) code:__ Since we're going to be running Gradient Descent a number of times let's package it into a function for convenience. Fill in the missing code in `GradientDescent()`, note that the missing code is going to look a lot like the provided code blocks in Q5 -- feel free to use those as a starting point.\n\n\n* __c) short response:__ Use the provided code to split the normalized data into a test and train set, then run 50 iterations of gradient descent and plot the MSE curves for each. Describe what you see and speculate about why this might be happening.\n\n\n* __d) short response:__ Note that passing the optional parameter `seed` to the Spark method `randomSplit` allows us to pseudo randomize our test/train split in a way that is replicable. Re-run the code for part 'c but this time in the line where we perform the `normedRDD.randomSplit` change the seed to _`seed = 5`_. What changes in the plot? Repeat for _`seed = 4`_. How does this change your interpret the results you saw in 'c'. What is the more likely explanation?"],"metadata":{}},{"cell_type":"markdown","source":["### Q5 Student Answers:\n> __a)__ \n\nWith each iteration of gradient descent, the OLS loss value of the model should go down towards **0**. Also, OLS loss on test/validation should go down with each iteration just like on the trained data. We can better see these loss values going down visually by plotting against the number of iterations instead of printing them. \n\n> __c)__ \n\nFrom the comparison plot of OLS loss for train_data and test_data, we can see that the loss is low for train_data than the test_data. This is due to the model was fitted/trained on the train_data, the model has seen the train_data when it was performing optimzation on the loss function. But this is not the case with the test_data and thus the OLS loss for test_data is slightly higher than train_data \n\n> __d)__ \n\nWhen the `seed` was set at **5**, the test_loss was initially lower than the training_loss until iteration_15. From iteration_15 to iteration_50, the training_loss was lower. \nWhen the `seed` was set at **4**, the test_loss was lower than the training_loss in each iteration. This is counterintuitive. This has happended because of the randomness in splitting the data. The test_data could have been more similar (almost like a subset) to the train_data and thus the test_loss was lower than the training_loss."],"metadata":{}},{"cell_type":"code","source":["# part b - OLS gradient descent function\ndef GradientDescent(trainRDD, testRDD, wInit, nSteps = 20, \n                    learningRate = 0.1, verbose = False):\n    \"\"\"\n    Perform nSteps iterations of OLS gradient descent and \n    track loss on a test and train set. Return lists of\n    test/train loss and the models themselves.\n    \"\"\"\n    # initialize lists to track model performance\n    train_history, test_history, model_history = [], [], []\n    \n    # perform n updates & compute test and train loss after each\n    model = wInit\n    for idx in range(nSteps): \n        \n        ############## YOUR CODE HERE #############\n        model = GDUpdate(trainRDD, model, learningRate)\n        training_loss = OLSLoss(trainRDD, model)\n        test_loss = OLSLoss(testRDD, model)\n        ############## (END) YOUR CODE #############\n        \n        # keep track of test/train loss for plotting\n        train_history.append(training_loss)\n        test_history.append(test_loss)\n        model_history.append(model)\n        \n        # console output if desired\n        if verbose:\n            print(\"----------\")\n            print(f\"STEP: {idx+1}\")\n            print(f\"training loss: {training_loss}\")\n            print(f\"test loss: {test_loss}\")\n            print(f\"Model: {[round(w,3) for w in model]}\")\n    return train_history, test_history, model_history"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["# plot error curves - RUN THIS CELL AS IS\ndef plotErrorCurves(trainLoss, testLoss, title = None):\n    \"\"\"\n    Helper function for plotting.\n    Args: trainLoss (list of MSE) , testLoss (list of MSE)\n    \"\"\"\n    fig, ax = plt.subplots(1,1,figsize = (16,8))\n    x = list(range(len(trainLoss)))[1:]\n    ax.plot(x, trainLoss[1:], 'k--', label='Training Loss')\n    ax.plot(x, testLoss[1:], 'r--', label='Test Loss')\n    ax.legend(loc='upper right', fontsize='x-large')\n    plt.xlabel('Number of Iterations')\n    plt.ylabel('Mean Squared Error')\n    if title:\n        plt.title(title)\n    display(plt.show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["# run 50 iterations (RUN THIS CELL AS IS)\nwInit = BASELINE\ntrainRDD, testRDD = normedRDD.randomSplit([0.8,0.2], seed = 2018)\nstart = time.time()\nMSEtrain, MSEtest, models = GradientDescent(trainRDD, testRDD, wInit, nSteps = 50)\nprint(f\"\\n... trained {len(models)} iterations in {time.time() - start} seconds\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n... trained 50 iterations in 13.274309396743774 seconds\n</div>"]}}],"execution_count":45},{"cell_type":"code","source":["# take a look (RUN THIS CELL AS IS)\nplotErrorCurves(MSEtrain, MSEtest, title = 'Ordinary Least Squares Regression' )"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["# save the models & their performance for comparison later (RUN THIS CELL AS IS)\nnp.savetxt(hw4_path_open + 'OLSmodels.csv', np.array(models), delimiter=',')\nnp.savetxt(hw4_path_open + 'OLSloss.csv', np.array([MSEtrain, MSEtest]), delimiter=',')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":47},{"cell_type":"code","source":["# take a look (RUN THIS CELL AS IS)\ndbutils.fs.put(hw4_path + 'ols_models.txt', str(models), True)\ndbutils.fs.put(hw4_path + 'ols_loss.txt', str([MSEtrain, MSEtest]), True)\n#plotErrorCurves(MSEtrain, MSEtest, title = 'Ordinary Least Squares Regression' )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote 10426 bytes.\nWrote 1988 bytes.\nOut[228]: True</div>"]}}],"execution_count":48},{"cell_type":"code","source":["# run 50 iterations (RUN THIS CELL AS IS)\nwInit = BASELINE\ntrainRDD, testRDD = normedRDD.randomSplit([0.8,0.2], seed = 5)\nstart = time.time()\nMSEtrain, MSEtest, models = GradientDescent(trainRDD, testRDD, wInit, nSteps = 50)\nprint(f\"\\n... trained {len(models)} iterations in {time.time() - start} seconds\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n... trained 50 iterations in 12.887319326400757 seconds\n</div>"]}}],"execution_count":49},{"cell_type":"code","source":["# take a look (RUN THIS CELL AS IS)\nplotErrorCurves(MSEtrain, MSEtest, title = 'Ordinary Least Squares Regression' )"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["# run 50 iterations (RUN THIS CELL AS IS)\nwInit = BASELINE\ntrainRDD, testRDD = normedRDD.randomSplit([0.8,0.2], seed = 4)\nstart = time.time()\nMSEtrain, MSEtest, models = GradientDescent(trainRDD, testRDD, wInit, nSteps = 50)\nprint(f\"\\n... trained {len(models)} iterations in {time.time() - start} seconds\")\n# take a look (RUN THIS CELL AS IS)\nplotErrorCurves(MSEtrain, MSEtest, title = 'Ordinary Least Squares Regression' )"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["# Question 6: Cross Validation\n\nIn question 5 we mentioned that computing the loss after each iteration is not strictly a part of Gradient Descent, its just convenient for visualizing our progress. This \"third step\" however comes with a tradeoff: it requires an extra pass through the data. Normally this would cause us to cringe except for the fact that both the loss computation and the gradient computation are very easy to parallelize - lots of the work can be done in place no shuffle needed for the aggregation. \n\n[Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)), sometimes called rotation estimation, or out-of-sample testing, is a model validation technique for assessing how well the model will generalize to an independent data set. The goal of cross-validation is to test the model's ability to predict new data. \n\nCross validation, which will solve the problem of the unreliable test-loss that we saw in question 5, presents a bit more of a scalability challenge. To avoid over-dependence on a particulary good or bad test/train split we divide the data into `k` roughly equal size parts and train `k` models. The `k-th` model is trained on all the data _except_ the `k-th` split which is used as a test set for that model. Finally we compute the loss by averaging together the test/train loss for each model. In this question we've provided a code base to perform gradient descent and cross validation in parallel. You'll fill in some of the key details based on your understanding from questions 1-5.\n\n#### From ISLR Chapter 5.1 - Cross Validation\n<img src=\"https://github.com/kyleiwaniec/w261_assets/blob/master/images/CV-ISLRp181.png?raw=true\">\n\n\n### Q6 Tasks:\n* __a) short response:__ A naive approach to training an OLS Regression model with cross validation might be to simply perform Gradient Descent on each of the 5 models in sequence. In this naive approach, how many total passes would be made over the data? [__`HINT:`__ _it will depend on factors that you should be able to name._]\n\n\n* __b) short response:__ Read through the provided helper function `kResiduals()` and note where it gets used in the subsequent function `CVLoss()`. For each record in the original dataset, how many tuples does `kResiduals()` emit? What are the keys of these newly emitted records? How will these keys help us compute cross validated loss?\n\n\n* __c) code:__ Complete the missing Spark code in `CVLoss()` so that this function returns the test/train cross validated error for a given set of data splits and their corresponding models. [__`TIP:`__ _your goal is to start from `partialLossRDD` and compute the test & train loss for each model so that the provided code can take the final average_].\n\n\n* __d) code:__ Read through the provided functions `partialGradients()` and `CVUpdate()`. These should have a familiar feel. Fill in the missing line in `CVUpdate()` to update each model and add the (new) array of coefficients to the `new_models` list. \n\n\n* __e) short response:__ Read `GradientDescent_withCV()` and then run the provided code to perform 50 iterations and plot the error curves. What can you conclude from this graph?"],"metadata":{}},{"cell_type":"markdown","source":["### Q6 Student Answers:\n> __a)__ \n\nThere will be one pass for each model if we perform cross validation with Gradient Descent to be in sequence. Here, it will be `5 passes` to accomplish the OLS Regression model. If we have 100 iterations to perform, then there will be 500 passes in total.\n\n> __b)__ \n\nFor each record in the original dataset, kResiduals() function will emit `total # of models (Here #models = 5)` number of tuples. Keys of the emitted records will be the concatenated string of modelNumber and train/test (`0-train`, `1-train`, `2-train`, `3-train`, `4-train`, `0-test`, `1-test`, `2-test`, `3-test`, `4-test` ). Once these records are emitted by all the datapoints, we can reduce them by the Key and sum it up to get the average. This value will be equivalent to the OLS loss.\n\n> __e)__ \n\nFrom the OLS loss curve for `training_loss` and `test_loss`, we can see that the loss values are closely aligned and consistently reduced. This is a good model fit as there is no overfitting on the training_data."],"metadata":{}},{"cell_type":"code","source":["# part b - helper function to emit residuals (RUN THIS CELL AS IS)\ndef kResiduals(dataPoint, models, splitNum):\n    \"\"\"\n    Compute the (squared) residuals for a data point given k different models.\n    Note that points from the k-th split are part of the test set for model number k\n    and part of the training set for all other models. We'll emit a key to track this.\n    Args:\n        dataPoint - tuple of (features_array, y)\n        models    - list of arrays representing model weights (bias at index 0)\n    Returns:\n        (stringFormattedKey, squared_error)\n    \"\"\"\n    # augment the data point with a bias term at index 0\n    X = np.append([1.0], dataPoint[0])\n    y = dataPoint[1]\n    # emit squared residuals for each model\n    for modelNum, W in enumerate(models):\n        if modelNum == splitNum:\n            yield(f\"{modelNum}-test\", (W.dot(X) - y)**2)\n        else:\n            yield(f\"{modelNum}-train\", (W.dot(X) - y)**2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["# part c - fill in the missing code below\ndef CVLoss(dataSplits, models):\n    \"\"\"\n    Compute the k-fold cross-validated test and train loss.\n    Args:\n        dataSplits - list of RDDs corresponding to the k test splits.\n        models     - list of k arrays representing model weights (bias at index 0)\n    Returns: \n        tuple of floats: (training_loss, test_loss)\n    \"\"\"\n    # compute k residuals for each dataPoint (one for each model)\n    partialLossRDD = sc.parallelize([])\n    for splitNum, splitRDD in enumerate(dataSplits):\n        residuals = splitRDD.flatMap(lambda x: kResiduals(x, models, splitNum))\n        partialLossRDD = sc.union([partialLossRDD, residuals])\n    \n    ################ YOUR CODE HERE #################        \n    loss = partialLossRDD.aggregateByKey((0,0), lambda x,y: (x[0] + y,    x[1] + 1), lambda x,y: (x[0] + y[0], x[1] + y[1])) \\\n                         .mapValues(lambda x: x[0]/x[1]) \\\n                         .collect()      \n    \n    ################ (END) YOUR CODE ################# \n    \n    test_loss = np.mean([x[1] for x in loss if x[0].split('-')[1] == 'test'])\n    training_loss = np.mean([x[1] for x in loss if x[0].split('-')[1] == 'train'])\n    return training_loss, test_loss"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":55},{"cell_type":"code","source":["# part d - helper function RUN THIS CELL AS IS\ndef partialGradients(splitNum, dataPoint, models):\n    \"\"\"\n    Emit partial gradient for this data point for each model.\n    NOTE: a data point from split-number k is in the test set for \n    model-k so we don't compute a partial gradient for that model.\n    \"\"\"\n    # augment the data point\n    X = np.append([1.0], dataPoint[0])\n    y = dataPoint[1]\n    # emit partial gradients for each model with a counter for averaging later\n    for modelNum, W in enumerate(models):\n        if modelNum != splitNum:\n            yield (modelNum, [(W.dot(X) - y)*X, 1])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"code","source":["# part d - perform GD updates for all k models (FILL IN MISSING CODE BELOW)\ndef CVUpdate(dataSplits, models, learningRate = 0.1):\n    \"\"\"\n    Compute gradients for k models given k corresponding dataSplits.\n    NOTE: the training set for model-k is all records EXCEPT those in the k-th split.\n    \"\"\"\n    # compute partial gradient k-1 times for each fold\n    partialsRDD = sc.parallelize([])\n    for splitNum, splitRDD in enumerate(dataSplits):\n        thisFoldPartialGrads = splitRDD.flatMap(lambda x: partialGradients(splitNum, x, models))\n        partialsRDD = sc.union([partialsRDD, thisFoldPartialGrads])\n\n    # compute gradients by taking the average partialGrad for each fold\n    gradients = partialsRDD.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\\\n                           .mapValues(lambda x: x[0]/x[1])\\\n                           .map(lambda x: x[1])\\\n                           .collect()\n    \n    # update all k models & return them in a list\n    new_models = []\n    for W, grad in zip(models, gradients):\n        ############# YOUR CODE HERE ############\n        new_models.append(W - (learningRate  *  grad))\n        ############# (END) YOUR CODE ###########\n    return new_models"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":57},{"cell_type":"code","source":["# part e - RUN THIS CELL AS IS\ndef GradientDescent_withCV(dataSplits, wInit, learningRate=0.1, nSteps = 5, verbose = False):\n    \"\"\"\n    Train k models in parallel and track cross validated test/train loss.\n    Returns:\n        train_hist - (list) of floats\n        test_hist - (list) of floats\n        model_hist - (list) of arrays representing model coefficients (bias at index 0)\n    \"\"\"\n    # broadcast initial models (one for each fold)\n    bModels = sc.broadcast([wInit] * len(dataSplits))\n    \n    \n    # initialize lists to track performance\n    train_loss_0, test_loss_0 = CVLoss(dataSplits, bModels.value)\n    train_hist, test_hist, model_hist = [train_loss_0], [test_loss_0], [wInit]\n    \n    # perform k gradient updates at a time (one for each fold)\n    start = time.time()\n    for step in range(nSteps):\n        new_models = CVUpdate(dataSplits, bModels.value, learningRate)\n           \n        bModels = sc.broadcast(new_models)\n\n        # log progress\n        train_loss, test_loss = CVLoss(dataSplits, bModels.value)\n        train_hist.append(train_loss)\n        test_hist.append(test_loss)\n        model_hist.append(new_models[0])\n        \n        if verbose:\n            print(\"-------------------\")\n            print(f\"STEP {step}: \")\n            print(f\"model 1: {[round(w,4) for w in new_models[0]]}\")\n            print(f\" train loss: {round(train_loss,4)}\")\n            print(f\" test loss: {round(test_loss,4)}\")\n            \n    print(f\"\\n... trained {nSteps} iterations in {time.time() - start} seconds\")\n    return train_hist, test_hist, model_hist\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"code","source":["# part d -  run 50 iterations (RUN THIS CELL AS IS)\ndataSplits = normedRDD.randomSplit([0.2, 0.2, 0.2, 0.2, 0.2], seed = 2018) \nwInit = BASELINE\ntrainLoss, testLoss, models = GradientDescent_withCV(dataSplits, wInit, learningRate=0.1, nSteps = 50, verbose = False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n... trained 50 iterations in 45.26963782310486 seconds\n</div>"]}}],"execution_count":59},{"cell_type":"code","source":["# part d - take a look (RUN THIS CELL AS IS)\nplotErrorCurves(trainLoss, testLoss, title = '5-fold Cross Validated Loss' )"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["# Question 7: Regularization.\n\nOur goal, as always, is to build a linear model that will extend well to unseen data. Chosing the right combination of features to optimize generalizability can be extremely computationally costly given that there are \\\\(2^{p}\\\\) potential models that can be built from \\\\(p\\\\) features. Traditional methods like forward selection would involve iteratively testing these options to asses which combinations of features achieve a statistically significant prediction.\n\nRidge Regression and Lasso Regression are two popular alternatives to OLS, which enable us to train generalizable models without the trouble of forward selection and/or manual feature selection.  Both methods take advantage of the bias-variance tradeoff by _shrinking_ the model coefficients towards 0 which reduces the variance of our model with little increase in bias. In practice this 'shrinkage' is achieved by adding a penalty (a.k.a. 'regularization') term to the means squared error loss function. In this question you will implement Gradient Descent with ridge and lasso regularization.\n\n__`IMPORTANT NOTE:`__ When performing regularization _do not_ include the bias in your regularization term calcultion (Recall, that throughout this assignment we've included the bias at index 0 in the vector of weights that is your model).\n\n### Q7 Tasks:\n* __a) short response:__ The regularization term for ridge regression is the square of the \\\\(L2\\\\) norm of the weights vector (i.e. the sum of squares of the coefficients) times the regularization parameter, \\\\(\\lambda\\\\). Write the formulas for both the loss function and the gradient for Ridge Regularization and explain what extra step this will add to our gradient descent algorithm.\n\n\n* __b) short response:__ The regularization term for lasso regression is the \\\\(L1\\\\) norm of the weights vector (i.e. the sum of the absolute values of the coefficients) times the regularization parameter, \\\\(\\lambda\\\\). Write the formulas for both the loss function and the gradient for Lasso Regularization and explain how the gradient descent update in Lasso will be different than it was in Ridge.\n\n\n* __c) code:__ Fill in the first two missing code blocks in `GDUpdate_wReg()` so that this function will perform a single parameter update using \\\\(L2\\\\) regularization if the parameter `regType` is set to `ridge`, \\\\(L1\\\\) regularization if set to `lasso` and unregularized OLS otherwise.\n\n\n* __d) code + short response:__ Use the provided code to train 50 iterations of ridge and lasso regression and plot the test/train error. Comment on the curves you see. Does this match your expectation?"],"metadata":{}},{"cell_type":"markdown","source":["### Q7 Student Answers:\n> __a)__ \n\nLoss function for `Ridge Regularized Regression`:\n\n\n\\\\( L(w) = [ \\frac{1}{n}\\sum_{i=1}^{n} (w^T \\cdot x_i - y_i)^2]  \\\\)\n\n\\\\( + [\\lambda \\cdot \\sum_{j=1}^{p} || w_j ||^2]  \\\\)\n\nGradient for `Ridge Regularized Regression`:\n\n\\\\( \\nabla L(w) =  2 \\cdot \\frac{1}{n}\\sum_{i=1}^{n} x_i \\cdot [w^T \\cdot x_i - y_i] \\\\)\n\n\\\\( + 2 \\cdot \\lambda \\cdot \\sum_{j=1}^{p} w_j  \\\\)\n\nThe `gradient` of ridge regression adds \\\\(  2 \\cdot \\lambda \\cdot \\sum_{j=1}^{p} w_j  \\\\) term in addition to the OLS gradient. \n\n> __b)__ \n\nLoss function for `LASSO Regularized Regression`:\n\n\n\\\\( L(w) = [ \\frac{1}{n}\\sum_{i=1}^{n} (w^T \\cdot x_i - y_i)^2]  \\\\)\n\n\\\\( + [\\lambda \\cdot \\sum_{j=1}^{p} |w_j|]  \\\\)\n\nGradient for `LASSO Regularized Regression`:\n\n\\\\( \\nabla L(w) =  2 \\cdot \\frac{1}{n}\\sum_{i=1}^{n} x_i \\cdot [w^T \\cdot x_i - y_i] \\\\)\n\n\\\\( + \\lambda \\cdot \\sum_{j=1}^{p} \\frac{w_j}{|w_j|}  \\\\)\n\nThe `gradient` of LASSO regression adds \\\\(  \\lambda \\cdot \\sum_{j=1}^{p} \\nabla |w_j|  \\\\) term in addition to the OLS gradient. \n\n> __d)__ \n\nFrom the Loss plots for Ridge and LASSO regression against iterations, we can see that the `training_loss` and `test_loss` are closely aligned. This shows that the model has `not overfitted` the training_data as is the case with the pure OLS regression. This is due to the added regularization made the model more generalizable and fitted the trainig_data and test_data equally well."],"metadata":{}},{"cell_type":"code","source":["# part c - gradient descent with regularization\ndef GDUpdate_wReg(dataRDD, W, learningRate = 0.1, regType = None, regParam = 0.1):\n    \"\"\"\n    Perform one gradient descent step/update with ridge or lasso regularization.\n    Args:\n        dataRDD - tuple of (features_array, y)\n        W       - (array) model coefficients with bias at index 0\n        learningRate - (float) defaults to 0.1\n        regType - (str) 'ridge' or 'lasso', defaults to None\n        regParam - (float) regularization term coefficient\n    Returns:\n        model   - (array) updated coefficients, bias still at index 0\n    \"\"\"\n    # augmented data\n    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n    \n    new_model = None\n    #################### YOUR CODE HERE ###################\n    if regType == None:\n        grad = 2 * augmentedData.map(lambda x: (W.dot(x[0]) - x[1]) * x[0]).mean()\n        new_model = W - (learningRate * grad)    \n    elif regType == 'ridge':\n        grad = (2 * augmentedData.map(lambda x: (W.dot(x[0]) - x[1]) * x[0]).mean() ) + (2 * regParam * (W[1:])).mean()\n        new_model = W - (learningRate * grad)         \n    elif regType == 'lasso':  \n        grad = (2 * augmentedData.map(lambda x: (W.dot(x[0]) - x[1]) * x[0]).mean()) + ( regParam * np.array([1 if w > 0 else -1  for w in W[1:]]) ).mean()\n        new_model = W - (learningRate * grad)   \n    ################## (END) YOUR CODE ####################\n    return new_model"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":63},{"cell_type":"code","source":["# part d - ridge/lasso gradient descent function\ndef GradientDescent_wReg(trainRDD, testRDD, wInit, nSteps = 20, learningRate = 0.1,\n                         regType = None, regParam = 0.1, verbose = False):\n    \"\"\"\n    Perform nSteps iterations of regularized gradient descent and \n    track loss on a test and train set. Return lists of\n    test/train loss and the models themselves.\n    \"\"\"\n    # initialize lists to track model performance\n    train_history, test_history, model_history = [], [], []\n    \n    # perform n updates & compute test and train loss after each\n    model = wInit\n    for idx in range(nSteps):  \n        # update the model\n        model = GDUpdate_wReg(trainRDD, model, learningRate, regType, regParam)\n        \n        # keep track of test/train loss for plotting\n        train_history.append(OLSLoss(trainRDD, model))\n        test_history.append(OLSLoss(testRDD, model))\n        model_history.append(model)\n        \n        # console output if desired\n        if verbose:\n            print(\"----------\")\n            print(f\"STEP: {idx+1}\")\n            print(f\"training loss: {training_loss}\")\n            print(f\"test loss: {test_loss}\")\n            print(f\"Model: {[round(w,3) for w in model]}\")\n    return train_history, test_history, model_history"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":64},{"cell_type":"code","source":["# run 50 iterations of ridge (RUN THIS CELL AS IS)\nwInit = BASELINE\ntrainRDD, testRDD = normedRDD.randomSplit([0.8,0.2], seed = 5)\nstart = time.time()\nridge_results = GradientDescent_wReg(trainRDD, testRDD, wInit, nSteps = 50,\n                                      regType='ridge', regParam = 0.05 )\nprint(f\"\\n... trained {len(ridge_results[2])} iterations in {time.time() - start} seconds\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n... trained 50 iterations in 12.03798770904541 seconds\n</div>"]}}],"execution_count":65},{"cell_type":"code","source":["# part d - save and display ridge results (RUN THIS CELL AS IS)\ntrainLoss, testLoss, models = ridge_results\ndbutils.fs.put(hw4_path + 'ridge_models.txt', str(models), True)\ndbutils.fs.put(hw4_path + 'ridge_loss.txt', str([trainLoss, testLoss]), True)\nplotErrorCurves(trainLoss, testLoss, title = 'Ridge Regression Error Curves' )"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["# run 50 iterations of lasso (RUN THIS CELL AS IS)\nwInit = BASELINE\ntrainRDD, testRDD = normedRDD.randomSplit([0.8,0.2], seed = 5)\nstart = time.time()\nlasso_results = GradientDescent_wReg(trainRDD, testRDD, wInit, nSteps = 50,\n                                     regType='lasso', regParam = 0.05)\nprint(f\"\\n... trained {len(lasso_results[2])} iterations in {time.time() - start} seconds\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n... trained 50 iterations in 11.860846996307373 seconds\n</div>"]}}],"execution_count":67},{"cell_type":"code","source":["# part d - save and display lasso results (RUN THIS CELL AS IS)\ntrainLoss, testLoss, models = lasso_results\ndbutils.fs.put(hw4_path + 'lasso_models.txt', str(models), True)\ndbutils.fs.put(hw4_path + 'lasso_loss.txt', str([trainLoss, testLoss]), True)\nplotErrorCurves(trainLoss, testLoss, title = 'Lasso Regression Error Curves' )"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":["# Question 8: Results\n\nIn this final question we'll use a few different plots to help us compare the OLS, Ridge and Lasso models that we have trained. Use the provided code to load the training history from file and retrieve the best (i.e. last) model from each method.\n\n### Q8 Tasks:\n* __a) code:__ Use the provided code to load the training history from file and retrieve the best (i.e. last) model from each method. Then compute the mean squared error on the held out dataset for each of the three models. [__`TIP:`__ _the held out data is in it's raw form, don't forget to parse and normalize before applying your calculations, you should also be careful to normalize using the same scaling parameters that you used for the training data._]\n\n* __b) short response:__ Which model performed best? Discuss how you interpret these results and what you would want to try next.\n\n\n* __c) short response:__ Use the provided code to plot side by side boxplots of the residuals vs. the outcome (i.e. `quality`). What can you observe about our model performance? [__`TIP:`__ _note that the heldout data set is plenty small enough to fit in memory so no need to sample. Feel free to do your plotting in pandas or any other comfortable python package._]\n\n\n* __d) short response:__ Run the provided code to visualize the model coefficients for the first 50 iterations of training. What do you observe about how the OLS, ridge and lasso coefficients change over the course of the training process. Please be sure to discuss all three in your response."],"metadata":{}},{"cell_type":"markdown","source":["### Q8 Student Answers:\n> __b)__ \n\nOLS regression model performed better than Ridge regression and LASSO regression model based on the Mean Squared Errors for the validation_data. This could be due to the large regularizing parameter \\\\( \\lambda \\\\) value. If we have a large \\\\( \\lambda \\\\) value, then the penalty term would be higher for the loss function and thus shrinks the weights closer to the zero. \n\n> __c)__ \n\nFrom the provided `get_residuals()` function for `8.c`, we can see that the residuals are defined as the difference between the `ground truth quality` to the `estimated quality` : \\\\( y - \\hat{y} \\\\)\n\nWe can make below inferences from the residual values:\n\n1. If a residual value is **zero** `0`, that means the model predicted correct for the data point. In our Boxplots, `quality_6` has a median value at zero, which means the predictions for quality_6 are `more accurate`.\n2. If a residual value is **negative** `(< 0)`, that means the model predicted higher quality for the data point. In our Boxplots, `quality_3`, `quality_4`, and `quality_5` have a median value less than zero, which means the predictions for these qualities are over predicted.\n3. If a residual value is **positive** `(0 >)`, that means the model predicted lower quality for the data point. In our Boxplots, `quality_7`, `quality_8`, and `quality_9` have a median value greater than zero, which means the predictions for these qualities are under predicted.\n\n\n> __d)__ \n\nIn OLS Regression, the coefficients are more widely spread and are more consistent\nIn Ridge Regression, the coefficients are closer to the zero (compared to the OLS coefficients) due to the regularizing effect on the coefficients. \nIn LASSO Regression, the coefficients are closer to the zero (compared to the OLS coefficients) due to the regularizing effect on the coefficients."],"metadata":{}},{"cell_type":"code","source":["# part a - load the models from file (RUN THIS CELL AS IS)\nridge_models = open(hw4_path_open + 'ridge_models.txt', 'r').read()\nlasso_models = open(hw4_path_open + 'lasso_models.txt', 'r').read()\nols_models = open(hw4_path_open + 'ols_models.txt', 'r').read()\nridge_models = np.array(ast.literal_eval(re.sub(r'[()\\n]','',re.sub('array', '', ridge_models))))\nlasso_models = np.array(ast.literal_eval(re.sub(r'[()\\n]','',re.sub('array', '', lasso_models))))\nols_models = np.array(ast.literal_eval(re.sub(r'[()\\n]','',re.sub('array', '', ols_models))))\nbest_ols = ols_models[-1,:]\nbest_ridge = ridge_models[-1,:]\nbest_lasso = lasso_models[-1,:]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":71},{"cell_type":"code","source":["# part a - compute MSE on the held out data for all three 'best' models\nolsMSE, ridgeMSE, lassoMSE = None, None, None\n############### YOUR CODE HERE #################\nfeatureMeans = trainRDDCached.map(lambda x: x[0]).mean()\nfeatureStdev = np.sqrt(trainRDDCached.map(lambda x: x[0]).variance())\n\nvalidationRDDCached = heldOutRDD.map(parse).cache()\nvalidationRDD = validationRDDCached.map(lambda x: ((x[0]-featureMeans)/ (np.sqrt(featureStdev)), x[1]))\n#validationRDD = normalize(validationRDDCached).cache() \n\nolsMSE = OLSLoss(validationRDD, best_ols)\nridgeMSE = OLSLoss(validationRDD, best_ridge)\nlassoMSE = OLSLoss(validationRDD, best_lasso)\n############### YOUR CODE HERE #################\n\nprint(f\"OLS Mean Squared Error: {olsMSE}\")\nprint(f\"Ridge Mean Squared Error: {ridgeMSE}\")\nprint(f\"Lasso Mean Squared Error: {lassoMSE}\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">OLS Mean Squared Error: 0.9011030208525092\nRidge Mean Squared Error: 0.9093685903783701\nLasso Mean Squared Error: 0.9729416454266311\n</div>"]}}],"execution_count":72},{"cell_type":"code","source":["# part c - helper function (RUN THIS CELL AS IS)\ndef get_residuals(dataRDD, model):\n    \"\"\"\n    Return a collected list of tuples (residual, quality_score)\n    \"\"\"\n    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n    residuals = augmentedData.map(lambda x: (x[1] - model.dot(x[0]), x[1]))\n    return residuals.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":73},{"cell_type":"code","source":["# part c - compute residuals for all three models (RUN THIS CELL AS IS)\nols_resid = np.array(get_residuals(validationRDD, best_ols))\nridge_resid = np.array(get_residuals(validationRDD, best_ridge))\nlasso_resid = np.array(get_residuals(validationRDD, best_lasso))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":74},{"cell_type":"code","source":["# part c - boxplots of residuals for all three models (RUN THIS CELL AS IS)\nfig, axes = plt.subplots(1, 3, figsize=(15,5))\nstuff_to_plot = zip(axes, [\"OLS\", \"Ridge\", \"Lasso\"], [ols_resid, ridge_resid, lasso_resid])\nfor ax, title, data in stuff_to_plot:\n    ax.set_title(title)\n    y = data[:, 0]\n    x = data[:, 1]\n    sns.boxplot(x, y, ax=ax)\nfig.suptitle(\"Prediction Error vs. Quality Score\", fontsize=15, y=0.98)\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["# part d - plotting function (RUN THIS CELL AS IS)\ndef plotCoeffs(models, featureNames, title):\n    \"\"\"\n    Helper Function to show how coefficients change as we train.\n    \"\"\"\n    fig, ax = plt.subplots(figsize = (15,8))\n    X = list(range(len(models)))\n    for data, name in zip(models.T, featureNames):\n        if name == \"Bias\":\n            continue\n        ax.plot(X, data, label=name)\n    ax.plot(X,[0]*len(X), 'k--')\n    plt.title(title)\n    plt.legend()\n    display(plt.show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":76},{"cell_type":"code","source":["# take a look (RUN THIS CELL AS IS)\nplotCoeffs(ols_models, ['Bias'] + FIELDS, \"OLS Coefficients over 50 GD steps\")"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["# take a look (RUN THIS CELL AS IS)\nplotCoeffs(ridge_models, ['Bias'] + FIELDS, \"Ridge Coefficients over 50 GD steps\")"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["# take a look (RUN THIS CELL AS IS)\nplotCoeffs(lasso_models, ['Bias'] + FIELDS, \"Lasso Coefficients over 50 GD steps\")"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"markdown","source":["### Congratulations, you have completed HW4! Please refer to the readme for submission instructions.\n\nIf you would like to provide feedback regarding this homework, please use the survey at: https://docs.google.com/forms/d/e/1FAIpQLScgIz4laP2JHChStLZx8MO0jGvrGyrOyQBnj7M4_4vcVXkB7g/viewform?usp=sf_link"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":81}],"metadata":{"name":"hw4_Workbook","notebookId":4030799983490467},"nbformat":4,"nbformat_minor":0}